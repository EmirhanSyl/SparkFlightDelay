{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "INPUT_CSV = \"data/airlines_delay.csv\"\n",
    "\n",
    "df = (spark.read\n",
    "      .option(\"header\", True)\n",
    "      .option(\"inferSchema\", True)\n",
    "      .csv(INPUT_CSV))\n",
    "\n",
    "df.printSchema()\n",
    "df.show(5, truncate=False)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df.select(\"Class\").groupBy(\"Class\").count().orderBy(\"Class\").show()\n",
    "\n",
    "# null var mı?\n",
    "df.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df.columns]).show(truncate=False)"
   ],
   "id": "74106f756791fecd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(\"train:\", train_df.count())\n",
    "print(\"test :\", test_df.count())\n"
   ],
   "id": "242064a4aed14345"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "label_col = \"Class\"\n",
    "\n",
    "cat_cols = [\"Airline\", \"AirportFrom\", \"AirportTo\"]\n",
    "num_cols = [\"Time\", \"Length\", \"DayOfWeek\"]  # Flight id gibi kolonlar varsa ekleme (gürültü olur)\n",
    "\n",
    "# Index + OHE\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=f\"{c}_idx\", handleInvalid=\"keep\") for c in cat_cols]\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[f\"{c}_idx\" for c in cat_cols],\n",
    "    outputCols=[f\"{c}_ohe\" for c in cat_cols],\n",
    "    handleInvalid=\"keep\"\n",
    ")\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=num_cols + [f\"{c}_ohe\" for c in cat_cols],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=label_col, maxIter=50, regParam=0.0)\n",
    "\n",
    "pipeline_lr = Pipeline(stages=indexers + [encoder, assembler, lr])\n",
    "\n",
    "model_lr = pipeline_lr.fit(train_df)\n",
    "pred_lr = model_lr.transform(test_df)\n",
    "\n",
    "pred_lr.select(\"features\", \"Class\", \"probability\", \"prediction\").show(5, truncate=False)\n"
   ],
   "id": "b3c9e904f8fb97d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "acc_eval = MulticlassClassificationEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "f1_eval  = MulticlassClassificationEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"f1\")\n",
    "auc_eval = BinaryClassificationEvaluator(labelCol=label_col, rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "\n",
    "acc = acc_eval.evaluate(pred_lr)\n",
    "f1  = f1_eval.evaluate(pred_lr)\n",
    "auc = auc_eval.evaluate(pred_lr)\n",
    "\n",
    "print(\"LogReg -> accuracy:\", acc)\n",
    "print(\"LogReg -> f1      :\", f1)\n",
    "print(\"LogReg -> AUC     :\", auc)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = (pred_lr\n",
    "      .groupBy(\"Class\")\n",
    "      .pivot(\"prediction\", [0.0, 1.0])\n",
    "      .count()\n",
    "      .na.fill(0)\n",
    "     )\n",
    "cm.show()\n"
   ],
   "id": "23a361a4e7050bf7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# (score, label) -> score: P(Class=1)\n",
    "score_and_labels = pred_lr.select(\n",
    "    F.col(\"probability\").getItem(1).alias(\"score\"),\n",
    "    F.col(\"Class\").cast(\"double\").alias(\"label\")\n",
    ").rdd.map(lambda r: (float(r[\"score\"]), float(r[\"label\"])))\n",
    "\n",
    "metrics = BinaryClassificationMetrics(score_and_labels)\n",
    "roc = metrics.roc().collect()  # [(FPR, TPR), ...]\n",
    "\n",
    "fpr = [p[0] for p in roc]\n",
    "tpr = [p[1] for p in roc]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve (Logistic Regression)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "24d5943a5466d045"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "gbt = GBTClassifier(labelCol=label_col, featuresCol=\"features\", maxIter=50, maxDepth=5)\n",
    "\n",
    "pipeline_gbt = Pipeline(stages=indexers + [encoder, assembler, gbt])\n",
    "model_gbt = pipeline_gbt.fit(train_df)\n",
    "pred_gbt = model_gbt.transform(test_df)\n",
    "\n",
    "acc_gbt = acc_eval.evaluate(pred_gbt)\n",
    "f1_gbt  = f1_eval.evaluate(pred_gbt)\n",
    "auc_gbt = auc_eval.evaluate(pred_gbt)\n",
    "\n",
    "print(\"GBT -> accuracy:\", acc_gbt)\n",
    "print(\"GBT -> f1      :\", f1_gbt)\n",
    "print(\"GBT -> AUC     :\", auc_gbt)\n"
   ],
   "id": "ae595c773551bc00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ML #2 — Route Clustering (KMeans, Unsupervised)\n",
    "\n",
    "Bu ikinci ML uygulaması: rotaları “gecikme profiline” göre kümeliyoruz."
   ],
   "id": "1eed94048065b195"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "route_df = (df\n",
    "    .groupBy(\"AirportFrom\", \"AirportTo\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"flight_count\"),\n",
    "        F.avg(\"Class\").alias(\"delay_rate\"),\n",
    "        F.avg(\"Length\").alias(\"avg_length\"),\n",
    "        F.avg(\"Time\").alias(\"avg_time\")\n",
    "    )\n",
    "    .filter(F.col(\"flight_count\") >= 50)   # az örnekli rotaları ele (istersen 20/100 yap)\n",
    ")\n",
    "\n",
    "route_df.show(5, truncate=False)\n",
    "print(\"Routes:\", route_df.count())\n"
   ],
   "id": "34f8813800b9feef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "route_assembler = VectorAssembler(\n",
    "    inputCols=[\"flight_count\", \"delay_rate\", \"avg_length\", \"avg_time\"],\n",
    "    outputCol=\"route_features\"\n",
    ")\n",
    "\n",
    "route_vec = route_assembler.transform(route_df)\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"route_features\", outputCol=\"route_features_scaled\", withStd=True, withMean=False)\n",
    "scaler_model = scaler.fit(route_vec)\n",
    "route_vec = scaler_model.transform(route_vec)\n",
    "\n",
    "evaluator = ClusteringEvaluator(featuresCol=\"route_features_scaled\", metricName=\"silhouette\", distanceMeasure=\"squaredEuclidean\")\n",
    "\n",
    "ks = list(range(2, 11))\n",
    "sil_scores = []\n",
    "\n",
    "for k in ks:\n",
    "    km = KMeans(k=k, seed=42, featuresCol=\"route_features_scaled\")\n",
    "    m = km.fit(route_vec)\n",
    "    p = m.transform(route_vec)\n",
    "    s = evaluator.evaluate(p)\n",
    "    sil_scores.append(s)\n",
    "    print(\"k:\", k, \"silhouette:\", s)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(ks, sil_scores, marker=\"o\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"silhouette\")\n",
    "plt.title(\"KMeans Silhouette vs k (Routes)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "20cd793e3d7d9029"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "best_k = ks[sil_scores.index(max(sil_scores))]\n",
    "print(\"Best k:\", best_k)\n",
    "\n",
    "kmeans = KMeans(k=best_k, seed=42, featuresCol=\"route_features_scaled\")\n",
    "kmeans_model = kmeans.fit(route_vec)\n",
    "route_clustered = kmeans_model.transform(route_vec)\n",
    "\n",
    "route_clustered.select(\"AirportFrom\", \"AirportTo\", \"flight_count\", \"delay_rate\", \"avg_length\", \"avg_time\", \"prediction\") \\\n",
    "               .orderBy(F.desc(\"delay_rate\")) \\\n",
    "               .show(20, truncate=False)\n",
    "\n",
    "# Küme özetleri (raporda çok iyi durur)\n",
    "cluster_summary = (route_clustered\n",
    "    .groupBy(\"prediction\")\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"num_routes\"),\n",
    "        F.avg(\"delay_rate\").alias(\"avg_delay_rate\"),\n",
    "        F.avg(\"flight_count\").alias(\"avg_flight_count\"),\n",
    "        F.avg(\"avg_length\").alias(\"avg_length\"),\n",
    "        F.avg(\"avg_time\").alias(\"avg_time\"),\n",
    "    )\n",
    "    .orderBy(\"prediction\")\n",
    ")\n",
    "\n",
    "cluster_summary.show(truncate=False)\n"
   ],
   "id": "22db1e13595b4fe5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
